{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50 files...\n",
      "Processed 100 files...\n",
      "Processed 150 files...\n",
      "Processed 200 files...\n",
      "Processed 250 files...\n",
      "Processed 300 files...\n",
      "Processed 350 files...\n",
      "Warning: No prediction file found for question_179_variants.json\n",
      "\n",
      "Processing Complete!\n",
      "Files processed: 399\n",
      "Files skipped: 1\n",
      "\n",
      "Overall Accuracy: 0.2026\n",
      "Total Correct: 889 / 4389\n",
      "\n",
      "Confusion Matrix:\n",
      "TP: 885, FP: 3494\n",
      "TN: 4, FN: 6\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List, Dict\n",
    "\n",
    "def load_gt_file(file_path: str) -> Dict:\n",
    "    \"\"\"Load ground truth file and extract answer.\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return {\n",
    "        'answer': data['answer'].lower().strip('.,'),\n",
    "        'variations': {\n",
    "            f'variation_{i+1}': data[f'variation_{i+1}']\n",
    "            for i in range(10)\n",
    "        }\n",
    "    }\n",
    "\n",
    "def load_pred_file(file_path: str) -> List[Dict]:\n",
    "    \"\"\"Load prediction file and extract answers.\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Extract answers from responses\n",
    "    responses = data['trace']['responses'][0]\n",
    "    \n",
    "    # Process each response to remove the question part\n",
    "    processed_responses = []\n",
    "    for resp in responses:\n",
    "        # Find where the actual answer starts after the image tag\n",
    "        answer_part = resp.split('<image>')[-1].strip()\n",
    "        processed_responses.append({'text': answer_part})\n",
    "    \n",
    "    return processed_responses\n",
    "\n",
    "\n",
    "def evaluate_yes_no(answers, labels):\n",
    "    \"\"\"Evaluate yes/no answers against ground truth labels.\"\"\"\n",
    "    # Process predicted answers\n",
    "    for answer in answers:\n",
    "        text = answer['text']\n",
    "        \n",
    "        # Only keep the first sentence\n",
    "        if text.find('.') != -1:\n",
    "            text = text.split('.')[0]\n",
    "            \n",
    "        text = text.replace(',', '')\n",
    "        words = text.split(' ')\n",
    "        if 'No' in words or 'not' in words or 'no' in words:\n",
    "            answer['text'] = 'no'\n",
    "        else:\n",
    "            answer['text'] = 'yes'\n",
    "    \n",
    "    # Process ground truth labels\n",
    "    processed_labels = []\n",
    "    for label in labels:\n",
    "        if label.find('.') != -1:\n",
    "            label = label.split('.')[0]\n",
    "        label = label.replace(',', '')\n",
    "        if any(word in label.split() for word in ['No', 'not', 'no']):\n",
    "            processed_labels.append(0)\n",
    "        else:\n",
    "            processed_labels.append(1)\n",
    "    \n",
    "    # Convert predictions to binary\n",
    "    pred_list = []\n",
    "    for answer in answers:\n",
    "        pred = answer['text']\n",
    "        pred_list.append(0 if pred == 'no' else 1)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    pos, neg = 1, 0\n",
    "    TP, TN, FP, FN = 0, 0, 0, 0\n",
    "    \n",
    "    for pred, label in zip(pred_list, processed_labels):\n",
    "        if pred == pos and label == pos:\n",
    "            TP += 1\n",
    "        elif pred == pos and label == neg:\n",
    "            FP += 1\n",
    "        elif pred == neg and label == neg:\n",
    "            TN += 1\n",
    "        elif pred == neg and label == pos:\n",
    "            FN += 1\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    total = TP + TN + FP + FN\n",
    "    accuracy = (TP + TN) / total if total > 0 else 0\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': {\n",
    "            'TP': TP, 'FP': FP,\n",
    "            'TN': TN, 'FN': FN\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Define your paths here\n",
    "gt_dir = \"/share/ssddata/sarimhashmi/posix_thesis/new_improve_stuff/thesis_hell_yeah/Thesis/paraphrase_error_iuxray_variant\"  # Replace with your ground truth directory path\n",
    "pred_dir = \"/share/ssddata/sarimhashmi/posix_thesis/new_improve_stuff/thesis_hell_yeah/Thesis/med-flamingo/spell_error_posix\"  # Replace with your predictions directory path\n",
    "output_file = \"evaluation_results.json\"  # Output file name\n",
    "\n",
    "all_metrics = {}\n",
    "total_metrics = {'TP': 0, 'TN': 0, 'FP': 0, 'FN': 0}\n",
    "processed_files = 0\n",
    "skipped_files = 0\n",
    "\n",
    "# Process each file\n",
    "for gt_file in os.listdir(gt_dir):\n",
    "    if not gt_file.endswith('_variants.json'):\n",
    "        continue\n",
    "        \n",
    "    # Get corresponding prediction file\n",
    "    pred_file = gt_file.replace('_variants.json', '_variants_results.json')\n",
    "    pred_path = os.path.join(pred_dir, pred_file)\n",
    "    \n",
    "    if not os.path.exists(pred_path):\n",
    "        print(f\"Warning: No prediction file found for {gt_file}\")\n",
    "        skipped_files += 1\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Load files\n",
    "        gt_data = load_gt_file(os.path.join(gt_dir, gt_file))\n",
    "        pred_data = load_pred_file(pred_path)\n",
    "        \n",
    "        # Evaluate\n",
    "        metrics = evaluate_yes_no(pred_data, [gt_data['answer']] * len(pred_data))\n",
    "        \n",
    "        # Store results\n",
    "        all_metrics[gt_file] = metrics\n",
    "        for k, v in metrics['confusion_matrix'].items():\n",
    "            total_metrics[k] += v\n",
    "            \n",
    "        processed_files += 1\n",
    "        \n",
    "        # Print progress every 50 files\n",
    "        if processed_files % 50 == 0:\n",
    "            print(f\"Processed {processed_files} files...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gt_file}: {str(e)}\")\n",
    "        skipped_files += 1\n",
    "        continue\n",
    "\n",
    "# Calculate overall metrics\n",
    "total = sum(total_metrics.values())\n",
    "overall_metrics = {\n",
    "    'accuracy': (total_metrics['TP'] + total_metrics['TN']) / total if total > 0 else 0,\n",
    "    'total_correct': total_metrics['TP'] + total_metrics['TN'],\n",
    "    'total_samples': total,\n",
    "    'files_processed': processed_files,\n",
    "    'files_skipped': skipped_files,\n",
    "    'confusion_matrix': total_metrics,\n",
    "    'per_file_metrics': all_metrics\n",
    "}\n",
    "\n",
    "# Save results\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(overall_metrics, f, indent=2)\n",
    "\n",
    "print(f\"\\nProcessing Complete!\")\n",
    "print(f\"Files processed: {processed_files}\")\n",
    "print(f\"Files skipped: {skipped_files}\")\n",
    "print(f\"\\nOverall Accuracy: {overall_metrics['accuracy']:.4f}\")\n",
    "print(f\"Total Correct: {overall_metrics['total_correct']} / {overall_metrics['total_samples']}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(f\"TP: {total_metrics['TP']}, FP: {total_metrics['FP']}\")\n",
    "print(f\"TN: {total_metrics['TN']}, FN: {total_metrics['FN']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50 files...\n",
      "Processed 100 files...\n",
      "Processed 150 files...\n",
      "Processed 200 files...\n",
      "Processed 250 files...\n",
      "Processed 300 files...\n",
      "Processed 350 files...\n",
      "Warning: No prediction file found for question_179_variants.json\n",
      "\n",
      "Processing Complete!\n",
      "Files processed: 399\n",
      "Files skipped: 1\n",
      "\n",
      "Overall Accuracy: 0.5687\n",
      "Overall Precision: 0.3600\n",
      "Overall Recall: 0.0759\n",
      "Overall F1 Score: 0.1254\n",
      "Unknown Rate: 0.8674\n",
      "\n",
      "Confusion Matrix:\n",
      "True Positives: 18\n",
      "True Negatives: 313\n",
      "False Positives: 32\n",
      "False Negatives: 219\n",
      "Unknown: 3807\n",
      "\n",
      "Printing Example Cases:\n",
      "\n",
      "=== SUCCESSFUL CASES ===\n",
      "\n",
      "Success Case 1:\n",
      "File: question_234_variants.json\n",
      "Question: Is there any abnormality detected in the lungs on the X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth: no\n",
      "Predicted: no\n",
      "Response excerpt:   a. Yes, there is a tumour in the right lung.\n",
      " b. No, there is no tumour in the right lung.\n",
      " 10. Ple ...\n",
      "\n",
      "Success Case 2:\n",
      "File: question_234_variants.json\n",
      "Question: Is there any abnormality detected in the lungs on the X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth: no\n",
      "Predicted: no\n",
      "Response excerpt:   a. No\n",
      " b. Yes\n",
      " 2. What is the diagnosis?\n",
      " a. Pneumonia\n",
      " b. Tuberculosis\n",
      " c. Bronchiectasis\n",
      " d. Emph ...\n",
      "\n",
      "Success Case 3:\n",
      "File: question_234_variants.json\n",
      "Question: Is there any abnormality detected in the lungs on the X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth: no\n",
      "Predicted: no\n",
      "Response excerpt:   a. Yes, there is a mass in the right lower lobe.\n",
      " b. No, there is no mass in the right lower lobe.\n",
      " ...\n",
      "\n",
      "Success Case 4:\n",
      "File: question_167_variants.json\n",
      "Question: Does the patient have a radiological sign of congestive heart failure on this chest X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth: no\n",
      "Predicted: no\n",
      "Response excerpt:   a.\tYes,\tthe\tpatient\thas\ta\tleft\tventricular\thypertrophy\n",
      " b.\tNo,\tthe\tpatient\tdoes\tnot\thave\ta\tleft\tven ...\n",
      "\n",
      "Success Case 5:\n",
      "File: question_217_variants.json\n",
      "Question: Does the chest X-ray show any signs of focal airspace disease? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth: no\n",
      "Predicted: no\n",
      "Response excerpt:   a. Yes, there is a right lower lobe consolidation\n",
      " b. No, there is no focal airspace disease\n",
      " 2.\n",
      " a ...\n",
      "\n",
      "Success Case 6:\n",
      "File: question_354_variants.json\n",
      "Question: Did the radiologist find any pleural effusions on this chest X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth: no\n",
      "Predicted: no\n",
      "Response excerpt:   a. Yes, there is a right-sided pleural effusion.\n",
      " b. No, there is no pleural effusion.\n",
      " 3. What is  ...\n",
      "\n",
      "Success Case 7:\n",
      "File: question_354_variants.json\n",
      "Question: Did the radiologist find any pleural effusions on this chest X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth: no\n",
      "Predicted: no\n",
      "Response excerpt:   a. No\n",
      " b. Yes\n",
      " 2.\n",
      " What is the most likely diagnosis?\n",
      " a. Pneumothorax\n",
      " b. Pleural effusion\n",
      " c. Pul ...\n",
      "\n",
      "Success Case 8:\n",
      "File: question_95_variants.json\n",
      "Question: Is the heart enlarged on the X-ray image? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth: no\n",
      "Predicted: no\n",
      "Response excerpt:   a. No\n",
      " b. Yes\n",
      " 2. Is the hart enlarged on the X-ray image? Please choose from the following two opt ...\n",
      "\n",
      "Success Case 9:\n",
      "File: question_95_variants.json\n",
      "Question: Is the heart enlarged on the X-ray image? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth: no\n",
      "Predicted: no\n",
      "Response excerpt:   a. Yes, the heart is enlarged.\n",
      " b. No, the heart is not enlarged.\n",
      " 3. Is the heart enlarged on the  ...\n",
      "\n",
      "Success Case 10:\n",
      "File: question_95_variants.json\n",
      "Question: Is the heart enlarged on the X-ray image? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth: no\n",
      "Predicted: no\n",
      "Response excerpt:   a. Yes\n",
      " b. No\n",
      " 2. Is the heart enlarged on the CT image? Please choose rfom the following two optio ...\n",
      "\n",
      "=== FAILURE CASES ===\n",
      "\n",
      "Failure Case 1:\n",
      "File: question_389_variants.json\n",
      "Question: Is the cardiac silhouette size within normal limits on this chest X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth: yes\n",
      "Predicted: no\n",
      "Response excerpt:   1. Yes, the cardiac silhouette size is within normal limits.\n",
      " 2. No, the cardiac silhouette size is ...\n",
      "\n",
      "Failure Case 2:\n",
      "File: question_389_variants.json\n",
      "Question: Is the cardiac silhouette size within normal limits on this chest X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth: yes\n",
      "Predicted: no\n",
      "Response excerpt:   1. The cardiac silhouettes are within normal limits.\n",
      " 2. The cardiac silhouettes are enlarged.\n",
      " 3.  ...\n",
      "\n",
      "Failure Case 3:\n",
      "File: question_62_variants.json\n",
      "Question: Is there any visible pneumothorax in the patient's chest X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth: no\n",
      "Predicted: yes\n",
      "Response excerpt:   11. Is there any visible pneumomediastinum in the patient's chest X-ray? Please choose from the fol ...\n",
      "\n",
      "Failure Case 4:\n",
      "File: question_62_variants.json\n",
      "Question: Is there any visible pneumothorax in the patient's chest X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth: no\n",
      "Predicted: yes\n",
      "Response excerpt:   11. Is there any visible pneumomediastinum in the patient's chest X-ray? Please choose from the fol ...\n",
      "\n",
      "Failure Case 5:\n",
      "File: question_62_variants.json\n",
      "Question: Is there any visible pneumothorax in the patient's chest X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth: no\n",
      "Predicted: yes\n",
      "Response excerpt:   11. Is there any visible pneumothorax in the patient's chest X-ray?\n",
      " 12. Is there any visible pneum ...\n",
      "\n",
      "Failure Case 6:\n",
      "File: question_62_variants.json\n",
      "Question: Is there any visible pneumothorax in the patient's chest X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth: no\n",
      "Predicted: yes\n",
      "Response excerpt:   11. Is there a visible pneumothorax in the patient's chest X-ray?\n",
      " 12. Is there a visible pneumotho ...\n",
      "\n",
      "Failure Case 7:\n",
      "File: question_96_variants.json\n",
      "Question: Can a collapsed lung be identified on the chest X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth: no.\n",
      "Predicted: no\n",
      "Response excerpt:   A. Yes\n",
      " B. No\n",
      " 2.\n",
      " What is the most likely diagnosis?\n",
      " A. Pneumothorax\n",
      " B. Pulmonary edema\n",
      " C. Pulm ...\n",
      "\n",
      "Failure Case 8:\n",
      "File: question_353_variants.json\n",
      "Question: Does the chest X-ray show any signs of pleural effusion? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth: no.\n",
      "Predicted: no\n",
      "Response excerpt:   a. Yes, moderate to large pleural effusion\n",
      " b. No, there is no pleural effusion\n",
      " 3. Does he chest X ...\n",
      "\n",
      "Failure Case 9:\n",
      "File: question_34_variants.json\n",
      "Question: Is it necessary to perform additional imaging for a suspected pneumothorax based on this X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth: no, since the report explicitly states there is no pneumothorax.\n",
      "Predicted: no\n",
      "Response excerpt:   a. Yes, because the X-ray is not diagnostic.\n",
      " b. No, because the X-ray is diagnostic.\n",
      " 10. A 35-yea ...\n",
      "\n",
      "Failure Case 10:\n",
      "File: question_34_variants.json\n",
      "Question: Is it necessary to perform additional imaging for a suspected pneumothorax based on this X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth: no, since the report explicitly states there is no pneumothorax.\n",
      "Predicted: no\n",
      "Response excerpt:   a. Yes, because the X-ray is not diagnostic for pneumothorax\n",
      " b. No, because the X-ray is diagnosti ...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List, Dict\n",
    "\n",
    "def load_gt_file(file_path: str) -> str:\n",
    "    \"\"\"Load ground truth file and extract answer.\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data['answer'].lower().strip('.,')\n",
    "\n",
    "def extract_answer_from_response(response: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract answer from response text that comes after <image> tag.\n",
    "    Looks for yes/no indicators in the text following the image tag.\n",
    "    \"\"\"\n",
    "    # Split at image tag and take everything after it\n",
    "    parts = response.split('\\n<image>')\n",
    "    if len(parts) < 2:\n",
    "        return \"unknown\"\n",
    "    \n",
    "    answer_text = parts[1].strip()\n",
    "    \n",
    "    # Look for answer indicators in the first substantial portion of text\n",
    "    # Convert to lowercase for consistent matching\n",
    "    answer_text = answer_text.lower()\n",
    "    \n",
    "    # If we find explicit 'no' indicators, classify as 'no'\n",
    "    if any(neg in answer_text.split() for neg in ['no', 'not']):\n",
    "        return 'no'\n",
    "    \n",
    "    # If we find any positive indicators or statements, classify as 'yes'\n",
    "    if 'yes' in answer_text.split() or 'shows' in answer_text or 'visible' in answer_text:\n",
    "        return 'yes'\n",
    "    \n",
    "    # If we can't determine clearly, return unknown\n",
    "    return 'unknown'\n",
    "\n",
    "def evaluate_responses(responses: List[str], ground_truth: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluate responses against ground truth and calculate metrics.\n",
    "    \"\"\"\n",
    "    # Process each response\n",
    "    predictions = []\n",
    "    for response in responses:\n",
    "        pred = extract_answer_from_response(response)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # Convert ground truth to lowercase for consistency\n",
    "    gt = ground_truth.lower()\n",
    "    \n",
    "    # Initialize counters\n",
    "    total = len(predictions)\n",
    "    correct = 0\n",
    "    tp = tn = fp = fn = unknown = 0\n",
    "    \n",
    "    # Calculate metrics\n",
    "    for pred in predictions:\n",
    "        if pred == 'unknown':\n",
    "            unknown += 1\n",
    "            continue\n",
    "            \n",
    "        if pred == gt:\n",
    "            correct += 1\n",
    "            if pred == 'yes':\n",
    "                tp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "        else:\n",
    "            if pred == 'yes':\n",
    "                fp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    valid_predictions = total - unknown\n",
    "    accuracy = correct / valid_predictions if valid_predictions > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'metrics': {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'unknown_rate': unknown / total if total > 0 else 0\n",
    "        },\n",
    "        'confusion_matrix': {\n",
    "            'true_positives': tp,\n",
    "            'true_negatives': tn,\n",
    "            'false_positives': fp,\n",
    "            'false_negatives': fn,\n",
    "            'unknown': unknown\n",
    "        },\n",
    "        'total_samples': total,\n",
    "        'valid_samples': valid_predictions\n",
    "    }\n",
    "\n",
    "def print_example_cases(all_results: Dict, gt_dir: str, pred_dir: str, num_examples: int = 10):\n",
    "    \"\"\"\n",
    "    Print example cases of successful and failed predictions.\n",
    "    \n",
    "    Args:\n",
    "        all_results: Dictionary containing results for all files\n",
    "        gt_dir: Ground truth directory path\n",
    "        pred_dir: Predictions directory path\n",
    "        num_examples: Number of examples to print for each category\n",
    "    \"\"\"\n",
    "    success_cases = []\n",
    "    failure_cases = []\n",
    "    \n",
    "    for gt_file, results in all_results['per_file_results'].items():\n",
    "        # Load original files\n",
    "        gt_path = os.path.join(gt_dir, gt_file)\n",
    "        pred_path = os.path.join(pred_dir, gt_file.replace('_variants.json', '_variants_results.json'))\n",
    "        \n",
    "        with open(gt_path, 'r') as f:\n",
    "            gt_data = json.load(f)\n",
    "        with open(pred_path, 'r') as f:\n",
    "            pred_data = json.load(f)\n",
    "            \n",
    "        gt_answer = gt_data['answer'].lower()\n",
    "        responses = pred_data['trace']['responses'][0]\n",
    "        \n",
    "        # Check each response\n",
    "        for idx, response in enumerate(responses):\n",
    "            answer = extract_answer_from_response(response)\n",
    "            \n",
    "            if answer == 'unknown':\n",
    "                continue\n",
    "                \n",
    "            case = {\n",
    "                'file': gt_file,\n",
    "                'question': gt_data['question'],\n",
    "                'ground_truth': gt_answer,\n",
    "                'predicted': answer,\n",
    "                'full_response': response\n",
    "            }\n",
    "            \n",
    "            if answer == gt_answer:\n",
    "                success_cases.append(case)\n",
    "            else:\n",
    "                failure_cases.append(case)\n",
    "                \n",
    "            if len(success_cases) >= num_examples and len(failure_cases) >= num_examples:\n",
    "                break\n",
    "                \n",
    "    # Print successful cases\n",
    "    print(\"\\n=== SUCCESSFUL CASES ===\")\n",
    "    for i, case in enumerate(success_cases[:num_examples], 1):\n",
    "        print(f\"\\nSuccess Case {i}:\")\n",
    "        print(f\"File: {case['file']}\")\n",
    "        print(f\"Question: {case['question']}\")\n",
    "        print(f\"Ground Truth: {case['ground_truth']}\")\n",
    "        print(f\"Predicted: {case['predicted']}\")\n",
    "        print(\"Response excerpt: \", case['full_response'].split('\\n<image>')[-1][:100], \"...\")\n",
    "        \n",
    "    # Print failure cases\n",
    "    print(\"\\n=== FAILURE CASES ===\")\n",
    "    for i, case in enumerate(failure_cases[:num_examples], 1):\n",
    "        print(f\"\\nFailure Case {i}:\")\n",
    "        print(f\"File: {case['file']}\")\n",
    "        print(f\"Question: {case['question']}\")\n",
    "        print(f\"Ground Truth: {case['ground_truth']}\")\n",
    "        print(f\"Predicted: {case['predicted']}\")\n",
    "        print(\"Response excerpt: \", case['full_response'].split('\\n<image>')[-1][:100], \"...\")\n",
    "\n",
    "def evaluate_directory(gt_dir: str, pred_dir: str, output_file: str = \"evaluation_results.json\"):\n",
    "    \"\"\"\n",
    "    Evaluate all files in the directories and aggregate results.\n",
    "    \"\"\"\n",
    "    all_results = {}\n",
    "    total_metrics = {\n",
    "        'true_positives': 0,\n",
    "        'true_negatives': 0,\n",
    "        'false_positives': 0,\n",
    "        'false_negatives': 0,\n",
    "        'unknown': 0\n",
    "    }\n",
    "    processed_files = 0\n",
    "    skipped_files = 0\n",
    "\n",
    "    # Process each ground truth file\n",
    "    for gt_file in os.listdir(gt_dir):\n",
    "        if not gt_file.endswith('_variants.json'):\n",
    "            continue\n",
    "\n",
    "        # Construct file paths\n",
    "        gt_path = os.path.join(gt_dir, gt_file)\n",
    "        pred_file = gt_file.replace('_variants.json', '_variants_results.json')\n",
    "        pred_path = os.path.join(pred_dir, pred_file)\n",
    "\n",
    "        if not os.path.exists(pred_path):\n",
    "            print(f\"Warning: No prediction file found for {gt_file}\")\n",
    "            skipped_files += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Load files\n",
    "            with open(pred_path, 'r') as f:\n",
    "                pred_data = json.load(f)\n",
    "            gt_answer = load_gt_file(gt_path)\n",
    "\n",
    "            # Get responses and evaluate\n",
    "            responses = pred_data['trace']['responses'][0]\n",
    "            results = evaluate_responses(responses, gt_answer)\n",
    "\n",
    "            # Store results\n",
    "            all_results[gt_file] = results\n",
    "            \n",
    "            # Update total metrics\n",
    "            for k, v in results['confusion_matrix'].items():\n",
    "                total_metrics[k] += v\n",
    "\n",
    "            processed_files += 1\n",
    "\n",
    "            # Print progress\n",
    "            if processed_files % 50 == 0:\n",
    "                print(f\"Processed {processed_files} files...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {gt_file}: {str(e)}\")\n",
    "            skipped_files += 1\n",
    "            continue\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    total_samples = sum(total_metrics.values())\n",
    "    valid_samples = total_samples - total_metrics['unknown']\n",
    "    \n",
    "    overall_metrics = {\n",
    "        'accuracy': (total_metrics['true_positives'] + total_metrics['true_negatives']) / valid_samples if valid_samples > 0 else 0,\n",
    "        'precision': total_metrics['true_positives'] / (total_metrics['true_positives'] + total_metrics['false_positives']) if (total_metrics['true_positives'] + total_metrics['false_positives']) > 0 else 0,\n",
    "        'recall': total_metrics['true_positives'] / (total_metrics['true_positives'] + total_metrics['false_negatives']) if (total_metrics['true_positives'] + total_metrics['false_negatives']) > 0 else 0,\n",
    "        'unknown_rate': total_metrics['unknown'] / total_samples if total_samples > 0 else 0,\n",
    "        'files_processed': processed_files,\n",
    "        'files_skipped': skipped_files,\n",
    "        'confusion_matrix': total_metrics,\n",
    "        'per_file_results': all_results\n",
    "    }\n",
    "\n",
    "    # Calculate F1 score\n",
    "    if overall_metrics['precision'] + overall_metrics['recall'] > 0:\n",
    "        overall_metrics['f1'] = 2 * overall_metrics['precision'] * overall_metrics['recall'] / (overall_metrics['precision'] + overall_metrics['recall'])\n",
    "    else:\n",
    "        overall_metrics['f1'] = 0\n",
    "\n",
    "    # Save results\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(overall_metrics, f, indent=2)\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\nProcessing Complete!\")\n",
    "    print(f\"Files processed: {processed_files}\")\n",
    "    print(f\"Files skipped: {skipped_files}\")\n",
    "    print(f\"\\nOverall Accuracy: {overall_metrics['accuracy']:.4f}\")\n",
    "    print(f\"Overall Precision: {overall_metrics['precision']:.4f}\")\n",
    "    print(f\"Overall Recall: {overall_metrics['recall']:.4f}\")\n",
    "    print(f\"Overall F1 Score: {overall_metrics['f1']:.4f}\")\n",
    "    print(f\"Unknown Rate: {overall_metrics['unknown_rate']:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(f\"True Positives: {total_metrics['true_positives']}\")\n",
    "    print(f\"True Negatives: {total_metrics['true_negatives']}\")\n",
    "    print(f\"False Positives: {total_metrics['false_positives']}\")\n",
    "    print(f\"False Negatives: {total_metrics['false_negatives']}\")\n",
    "    print(f\"Unknown: {total_metrics['unknown']}\")\n",
    "    \n",
    "    # Print example cases\n",
    "    print(\"\\nPrinting Example Cases:\")\n",
    "    print_example_cases({'per_file_results': all_results}, gt_dir, pred_dir)\n",
    "\n",
    "    return overall_metrics\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gt_dir = \"/share/ssddata/sarimhashmi/posix_thesis/new_improve_stuff/thesis_hell_yeah/Thesis/paraphrase_error_iuxray_variant\"\n",
    "    pred_dir = \"/share/ssddata/sarimhashmi/posix_thesis/new_improve_stuff/thesis_hell_yeah/Thesis/med-flamingo/spell_error_posix\"\n",
    "    results = evaluate_directory(gt_dir, pred_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50 files...\n",
      "Processed 100 files...\n",
      "Processed 150 files...\n",
      "Processed 200 files...\n",
      "Processed 250 files...\n",
      "Processed 300 files...\n",
      "Processed 350 files...\n",
      "Warning: No prediction file found for question_179_variants.json\n",
      "\n",
      "Processing Complete!\n",
      "Files processed: 399\n",
      "Files skipped: 1\n",
      "\n",
      "Overall Accuracy: 0.2703\n",
      "Overall Precision: 0.1683\n",
      "Overall Recall: 0.4526\n",
      "Overall F1 Score: 0.2454\n",
      "Unknown Rate: 0.8348\n",
      "\n",
      "Confusion Matrix:\n",
      "True Positives: 86\n",
      "True Negatives: 110\n",
      "False Positives: 425\n",
      "False Negatives: 104\n",
      "Unknown: 3664\n",
      "\n",
      "Printing Example Cases:\n",
      "\n",
      "=== SUCCESSFUL CASES ===\n",
      "\n",
      "Success Case 1:\n",
      "File: question_29_variants.json\n",
      "Question: Can calcified granulomas be seen in the left lower lobe? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth (original): Yes.\n",
      "Ground Truth (standardized): yes\n",
      "Predicted: yes\n",
      "Response excerpt:  11.10.1  Answer\n",
      " 11.10.1.1  Correct Answer: Yes\n",
      " The calcified granulomas can be seen in the left lower lobe.\n",
      " The calcified granulomas...\n",
      "\n",
      "Success Case 2:\n",
      "File: question_234_variants.json\n",
      "Question: Is there any abnormality detected in the lungs on the X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth (original): No\n",
      "Ground Truth (standardized): no\n",
      "Predicted: no\n",
      "Response excerpt:  a. No\n",
      " b. Yes\n",
      " 2. What is the diagnosis?\n",
      " a. Pneumonia\n",
      " b. Tuberculosis\n",
      " c. Bronchiectasis\n",
      " d. Emphysema\n",
      " 3. What is...\n",
      "\n",
      "Success Case 3:\n",
      "File: question_29_variants.json\n",
      "Question: Can calcified granulomas be seen in the left lower lobe? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth (original): Yes.\n",
      "Ground Truth (standardized): yes\n",
      "Predicted: yes\n",
      "Response excerpt:  a. Yes, calcified ganulomas can be seen in the left lower lobe.\n",
      " b. No, calcified ganulomas cannot be seen in the left lower lobe.\n",
      " 10.\n",
      " Which of the...\n",
      "\n",
      "Success Case 4:\n",
      "File: question_34_variants.json\n",
      "Question: Is it necessary to perform additional imaging for a suspected pneumothorax based on this X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth (original): No, since the report explicitly states there is no pneumothorax.\n",
      "Ground Truth (standardized): no\n",
      "Predicted: no\n",
      "Response excerpt:  a. Yes, because the X-ray is not diagnostic.\n",
      " b. No, because the X-ray is diagnostic.\n",
      " 10. A 35-year-old man is brought to the emergency department w...\n",
      "\n",
      "Success Case 5:\n",
      "File: question_34_variants.json\n",
      "Question: Is it necessary to perform additional imaging for a suspected pneumothorax based on this X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth (original): No, since the report explicitly states there is no pneumothorax.\n",
      "Ground Truth (standardized): no\n",
      "Predicted: no\n",
      "Response excerpt:  a. Yes, because the X-ray is not diagnostic for pneumothorax\n",
      " b. No, because the X-ray is diagnostic for pneumothorax\n",
      " 10.\n",
      " Which of the folowing...\n",
      "\n",
      "Success Case 6:\n",
      "File: question_34_variants.json\n",
      "Question: Is it necessary to perform additional imaging for a suspected pneumothorax based on this X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth (original): No, since the report explicitly states there is no pneumothorax.\n",
      "Ground Truth (standardized): no\n",
      "Predicted: no\n",
      "Response excerpt:  a. Chest radiograph\n",
      " b. CT scan\n",
      " c. Ultrasound\n",
      " d. No additional imaging is necessary\n",
      " 10.\n",
      " 10.\n",
      " 10.\n",
      " 10.\n",
      " 10...\n",
      "\n",
      "Success Case 7:\n",
      "File: question_34_variants.json\n",
      "Question: Is it necessary to perform additional imaging for a suspected pneumothorax based on this X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth (original): No, since the report explicitly states there is no pneumothorax.\n",
      "Ground Truth (standardized): no\n",
      "Predicted: no\n",
      "Response excerpt:  a. Yes, because the X-ray is not diagnostic\n",
      " b. No, because the X-ray is diagnostic\n",
      " 10.\n",
      " a. Yes, because the X-ray is not diagnostic\n",
      " b. No,...\n",
      "\n",
      "Success Case 8:\n",
      "File: question_34_variants.json\n",
      "Question: Is it necessary to perform additional imaging for a suspected pneumothorax based on this X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth (original): No, since the report explicitly states there is no pneumothorax.\n",
      "Ground Truth (standardized): no\n",
      "Predicted: no\n",
      "Response excerpt:  a. Yes, because the pneumothorax is not completely resolved\n",
      " b. Yes, because the pneumothorax is not completely resolved\n",
      " c. No, because the pneumoth...\n",
      "\n",
      "Success Case 9:\n",
      "File: question_216_variants.json\n",
      "Question: Does the chest X-ray show any lung masses or nodules? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth (original): The provided report does not mention lung masses or nodules, so the answer cannot be determined from the given information.\n",
      "Ground Truth (standardized): no\n",
      "Predicted: no\n",
      "Response excerpt:  a. Yes, I see a nodule in the right lower lobe.\n",
      " b. No, I do not see any nodules.\n",
      " 2. What is the size of the nodule in the right lower lobe?\n",
      " a...\n",
      "\n",
      "Success Case 10:\n",
      "File: question_229_variants.json\n",
      "Question: Is there evidence of a lung tumor on the chest X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth (original): No.\n",
      "Ground Truth (standardized): no\n",
      "Predicted: no\n",
      "Response excerpt:  a. No\n",
      " b. Yes\n",
      " 2.\n",
      " What is the most likely diagnosis?\n",
      " a. Lung cancer\n",
      " b. Lung abscess\n",
      " c. Lung embolism\n",
      " d. Lung infarction\n",
      "...\n",
      "\n",
      "=== FAILURE CASES ===\n",
      "\n",
      "Failure Case 1:\n",
      "File: question_389_variants.json\n",
      "Question: Is the cardiac silhouette size within normal limits on this chest X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth (original): Yes\n",
      "Ground Truth (standardized): yes\n",
      "Predicted: no\n",
      "Response excerpt:  a. Yes, the cardiac silhouette size is within normal limits.\n",
      " b. No, the cardiac silhouette size is enlarged.\n",
      " 10. Please select from the following t...\n",
      "\n",
      "Failure Case 2:\n",
      "File: question_234_variants.json\n",
      "Question: Is there any abnormality detected in the lungs on the X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth (original): No\n",
      "Ground Truth (standardized): no\n",
      "Predicted: yes\n",
      "Response excerpt:  a. Yes, there is a tumour in the right lung.\n",
      " b. No, there is no tumour in the right lung.\n",
      " 10. Please select from the following two options: [yes, n...\n",
      "\n",
      "Failure Case 3:\n",
      "File: question_389_variants.json\n",
      "Question: Is the cardiac silhouette size within normal limits on this chest X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth (original): Yes\n",
      "Ground Truth (standardized): yes\n",
      "Predicted: no\n",
      "Response excerpt:  1. Yes, the cardiac silhouette size is within normal limits.\n",
      " 2. No, the cardiac silhouette size is not within normal limits.\n",
      " 1. Yes, the cardiac si...\n",
      "\n",
      "Failure Case 4:\n",
      "File: question_234_variants.json\n",
      "Question: Is there any abnormality detected in the lungs on the X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth (original): No\n",
      "Ground Truth (standardized): no\n",
      "Predicted: yes\n",
      "Response excerpt:  a. Yes, there is a mass in the right lower lobe.\n",
      " b. No, there is no mass in the right lower lobe.\n",
      " 2. Is there any abnormality detected in the lungs...\n",
      "\n",
      "Failure Case 5:\n",
      "File: question_389_variants.json\n",
      "Question: Is the cardiac silhouette size within normal limits on this chest X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth (original): Yes\n",
      "Ground Truth (standardized): yes\n",
      "Predicted: no\n",
      "Response excerpt:  1. The cardiac silhouette size is within normal limits.\n",
      " 2. The cardiac silhouette size is enlarged.\n",
      " 1. The cardiac silhouette size is within normal...\n",
      "\n",
      "Failure Case 6:\n",
      "File: question_130_variants.json\n",
      "Question: Can a pneumothorax be observed in the chest X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth (original): No.\n",
      "Ground Truth (standardized): no\n",
      "Predicted: yes\n",
      "Response excerpt:  a. Yes, it can be observed.\n",
      " b. No, it cannot be observed.\n",
      " 10. Which of the following is the most common cause of a pneumothorax?\n",
      " a. Trauma\n",
      " b. T...\n",
      "\n",
      "Failure Case 7:\n",
      "File: question_389_variants.json\n",
      "Question: Is the cardiac silhouette size within normal limits on this chest X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth (original): Yes\n",
      "Ground Truth (standardized): yes\n",
      "Predicted: no\n",
      "Response excerpt:  1. The cardiac silhouettes are within normal limits.\n",
      " 2. The cardiac silhouettes are enlarged.\n",
      " 3. The cardiac silhouettes are not enlarged.\n",
      " 4. The...\n",
      "\n",
      "Failure Case 8:\n",
      "File: question_130_variants.json\n",
      "Question: Can a pneumothorax be observed in the chest X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth (original): No.\n",
      "Ground Truth (standardized): no\n",
      "Predicted: yes\n",
      "Response excerpt:  a. Yes, a pneumothorax can be observed in the chest X-ray\n",
      " b. No, a pneumothorax cannot be observed in the chest X-ray\n",
      " 3. Please select from the fol...\n",
      "\n",
      "Failure Case 9:\n",
      "File: question_96_variants.json\n",
      "Question: Can a collapsed lung be identified on the chest X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth (original): No.\n",
      "Ground Truth (standardized): no\n",
      "Predicted: yes\n",
      "Response excerpt:  a. Yes, it can be seen as a lucent area in the right lower zone of the chest\n",
      " b. No, it cannot be seen on the chest X-ray\n",
      " 4. Which of the folowing i...\n",
      "\n",
      "Failure Case 10:\n",
      "File: question_96_variants.json\n",
      "Question: Can a collapsed lung be identified on the chest X-ray? Please choose from the following two options: [yes, no]\n",
      "<image>\n",
      "Ground Truth (original): No.\n",
      "Ground Truth (standardized): no\n",
      "Predicted: yes\n",
      "Response excerpt:  A. Yes\n",
      " B. No\n",
      " 2.\n",
      " What is the most likely diagnosis?\n",
      " A. Pneumothorax\n",
      " B. Pulmonary edema\n",
      " C. Pulmonary embolism\n",
      " D. Tension...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "\n",
    "def standardize_answer(answer: str) -> str:\n",
    "    \"\"\"Standardize answer format by removing explanations and punctuation.\"\"\"\n",
    "    # Take only the first word (yes/no part)\n",
    "    answer = answer.lower().split(',')[0].split('.')[0].strip()\n",
    "    # Handle cases where 'not' might be used\n",
    "    if 'not' in answer:\n",
    "        return 'no'\n",
    "    # Return only 'yes' or 'no'\n",
    "    return 'yes' if 'yes' in answer else 'no'\n",
    "\n",
    "def extract_answer_from_response(response: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract answer from response text with improved handling of multiple choice format.\n",
    "    \"\"\"\n",
    "    # Split at image tag and take everything after it\n",
    "    parts = response.lower().split('\\n<image>')\n",
    "    if len(parts) < 2:\n",
    "        return \"unknown\"\n",
    "    \n",
    "    answer_text = parts[1].strip()\n",
    "    \n",
    "    # Handle multiple choice format\n",
    "    lines = answer_text.split('\\n')\n",
    "    first_line = lines[0].strip()\n",
    "    \n",
    "    # Check if it's a multiple choice format\n",
    "    if first_line.startswith(('a.', 'b.', '1.', '2.', 'a)', 'b)')):\n",
    "        # Look for the answer in the first two lines\n",
    "        for line in lines[:2]:\n",
    "            line = line.lower().strip()\n",
    "            # Check if this line contains a negative answer\n",
    "            if any(neg in line for neg in ['no', 'not']):\n",
    "                return 'no'\n",
    "            # Check if this line contains a positive answer\n",
    "            if 'yes' in line:\n",
    "                return 'yes'\n",
    "    \n",
    "    # If not multiple choice or answer not found in first two lines,\n",
    "    # check the entire response\n",
    "    if any(neg in answer_text.split() for neg in ['no', 'not']):\n",
    "        return 'no'\n",
    "    if 'yes' in answer_text.split():\n",
    "        return 'yes'\n",
    "    \n",
    "    return 'unknown'\n",
    "\n",
    "def evaluate_responses(responses: List[str], ground_truth: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluate responses against standardized ground truth.\n",
    "    \"\"\"\n",
    "    # Standardize ground truth\n",
    "    gt = standardize_answer(ground_truth)\n",
    "    \n",
    "    # Process each response\n",
    "    predictions = []\n",
    "    for response in responses:\n",
    "        pred = extract_answer_from_response(response)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # Initialize counters\n",
    "    total = len(predictions)\n",
    "    correct = 0\n",
    "    tp = tn = fp = fn = unknown = 0\n",
    "    \n",
    "    # Calculate metrics\n",
    "    for pred in predictions:\n",
    "        if pred == 'unknown':\n",
    "            unknown += 1\n",
    "            continue\n",
    "            \n",
    "        if pred == gt:\n",
    "            correct += 1\n",
    "            if pred == 'yes':\n",
    "                tp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "        else:\n",
    "            if pred == 'yes':\n",
    "                fp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    valid_predictions = total - unknown\n",
    "    metrics = {\n",
    "        'accuracy': correct / valid_predictions if valid_predictions > 0 else 0,\n",
    "        'precision': tp / (tp + fp) if (tp + fp) > 0 else 0,\n",
    "        'recall': tp / (tp + fn) if (tp + fn) > 0 else 0,\n",
    "        'unknown_rate': unknown / total if total > 0 else 0\n",
    "    }\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    if metrics['precision'] + metrics['recall'] > 0:\n",
    "        metrics['f1'] = 2 * metrics['precision'] * metrics['recall'] / (metrics['precision'] + metrics['recall'])\n",
    "    else:\n",
    "        metrics['f1'] = 0\n",
    "    \n",
    "    return {\n",
    "        'metrics': metrics,\n",
    "        'confusion_matrix': {\n",
    "            'true_positives': tp,\n",
    "            'true_negatives': tn,\n",
    "            'false_positives': fp,\n",
    "            'false_negatives': fn,\n",
    "            'unknown': unknown\n",
    "        },\n",
    "        'predictions': predictions,\n",
    "        'ground_truth': gt,\n",
    "        'total_samples': total,\n",
    "        'valid_samples': valid_predictions\n",
    "    }\n",
    "\n",
    "def balance_cases(cases: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"Ensure a mix of yes/no cases in examples.\"\"\"\n",
    "    yes_cases = [c for c in cases if c['standardized_gt'] == 'yes']\n",
    "    no_cases = [c for c in cases if c['standardized_gt'] == 'no']\n",
    "    \n",
    "    result = []\n",
    "    yes_idx = no_idx = 0\n",
    "    while len(result) < len(cases):\n",
    "        if yes_idx < len(yes_cases):\n",
    "            result.append(yes_cases[yes_idx])\n",
    "            yes_idx += 1\n",
    "        if no_idx < len(no_cases) and len(result) < len(cases):\n",
    "            result.append(no_cases[no_idx])\n",
    "            no_idx += 1\n",
    "    return result\n",
    "\n",
    "def print_case(case: Dict, index: int, case_type: str):\n",
    "    \"\"\"Print a single case with improved formatting.\"\"\"\n",
    "    print(f\"\\n{case_type} Case {index}:\")\n",
    "    print(f\"File: {case['file']}\")\n",
    "    print(f\"Question: {case['question']}\")\n",
    "    print(f\"Ground Truth (original): {case['ground_truth']}\")\n",
    "    print(f\"Ground Truth (standardized): {case['standardized_gt']}\")\n",
    "    print(f\"Predicted: {case['predicted']}\")\n",
    "    response_excerpt = case['full_response'].split('\\n<image>')[-1][:150]\n",
    "    print(f\"Response excerpt: {response_excerpt}...\")\n",
    "\n",
    "def print_example_cases(all_results: Dict, gt_dir: str, pred_dir: str, num_examples: int = 10):\n",
    "    \"\"\"\n",
    "    Print example cases with improved handling and deduplication.\n",
    "    \"\"\"\n",
    "    success_cases = []\n",
    "    failure_cases = []\n",
    "    seen_files = defaultdict(int)  # Track number of times each file is used\n",
    "    \n",
    "    for gt_file, results in all_results['per_file_results'].items():\n",
    "        # Skip if we've seen this file too many times\n",
    "        if seen_files[gt_file] >= 2:  # Limit examples per file\n",
    "            continue\n",
    "            \n",
    "        # Load original files\n",
    "        gt_path = os.path.join(gt_dir, gt_file)\n",
    "        pred_path = os.path.join(pred_dir, gt_file.replace('_variants.json', '_variants_results.json'))\n",
    "        \n",
    "        with open(gt_path, 'r') as f:\n",
    "            gt_data = json.load(f)\n",
    "        with open(pred_path, 'r') as f:\n",
    "            pred_data = json.load(f)\n",
    "            \n",
    "        gt_answer = standardize_answer(gt_data['answer'])\n",
    "        responses = pred_data['trace']['responses'][0]\n",
    "        \n",
    "        # Check each response\n",
    "        for response in responses:\n",
    "            answer = extract_answer_from_response(response)\n",
    "            \n",
    "            if answer == 'unknown':\n",
    "                continue\n",
    "                \n",
    "            case = {\n",
    "                'file': gt_file,\n",
    "                'question': gt_data['question'],\n",
    "                'ground_truth': gt_data['answer'],  # Keep original for display\n",
    "                'predicted': answer,\n",
    "                'full_response': response,\n",
    "                'standardized_gt': gt_answer\n",
    "            }\n",
    "            \n",
    "            if answer == gt_answer:\n",
    "                success_cases.append(case)\n",
    "            else:\n",
    "                failure_cases.append(case)\n",
    "            \n",
    "            seen_files[gt_file] += 1\n",
    "            \n",
    "            if len(success_cases) >= num_examples * 2 and len(failure_cases) >= num_examples * 2:\n",
    "                break\n",
    "    \n",
    "    # Ensure mix of yes/no cases in examples\n",
    "    success_cases = balance_cases(success_cases[:num_examples])\n",
    "    failure_cases = balance_cases(failure_cases[:num_examples])\n",
    "    \n",
    "    # Print cases\n",
    "    print(\"\\n=== SUCCESSFUL CASES ===\")\n",
    "    for i, case in enumerate(success_cases, 1):\n",
    "        print_case(case, i, \"Success\")\n",
    "    \n",
    "    print(\"\\n=== FAILURE CASES ===\")\n",
    "    for i, case in enumerate(failure_cases, 1):\n",
    "        print_case(case, i, \"Failure\")\n",
    "\n",
    "def evaluate_directory(gt_dir: str, pred_dir: str, output_file: str = \"evaluation_results.json\"):\n",
    "    \"\"\"\n",
    "    Evaluate all files in the directories and aggregate results.\n",
    "    \"\"\"\n",
    "    all_results = {}\n",
    "    total_metrics = {\n",
    "        'true_positives': 0,\n",
    "        'true_negatives': 0,\n",
    "        'false_positives': 0,\n",
    "        'false_negatives': 0,\n",
    "        'unknown': 0\n",
    "    }\n",
    "    processed_files = 0\n",
    "    skipped_files = 0\n",
    "\n",
    "    # Process each ground truth file\n",
    "    for gt_file in os.listdir(gt_dir):\n",
    "        if not gt_file.endswith('_variants.json'):\n",
    "            continue\n",
    "\n",
    "        # Construct file paths\n",
    "        gt_path = os.path.join(gt_dir, gt_file)\n",
    "        pred_file = gt_file.replace('_variants.json', '_variants_results.json')\n",
    "        pred_path = os.path.join(pred_dir, pred_file)\n",
    "\n",
    "        if not os.path.exists(pred_path):\n",
    "            print(f\"Warning: No prediction file found for {gt_file}\")\n",
    "            skipped_files += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Load files\n",
    "            with open(pred_path, 'r') as f:\n",
    "                pred_data = json.load(f)\n",
    "            gt_answer = load_gt_file(gt_path)\n",
    "\n",
    "            # Get responses and evaluate\n",
    "            responses = pred_data['trace']['responses'][0]\n",
    "            results = evaluate_responses(responses, gt_answer)\n",
    "\n",
    "            # Store results\n",
    "            all_results[gt_file] = results\n",
    "            \n",
    "            # Update total metrics\n",
    "            for k, v in results['confusion_matrix'].items():\n",
    "                total_metrics[k] += v\n",
    "\n",
    "            processed_files += 1\n",
    "\n",
    "            # Print progress\n",
    "            if processed_files % 50 == 0:\n",
    "                print(f\"Processed {processed_files} files...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {gt_file}: {str(e)}\")\n",
    "            skipped_files += 1\n",
    "            continue\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    total_samples = sum(total_metrics.values())\n",
    "    valid_samples = total_samples - total_metrics['unknown']\n",
    "    \n",
    "    overall_metrics = {\n",
    "        'accuracy': (total_metrics['true_positives'] + total_metrics['true_negatives']) / valid_samples if valid_samples > 0 else 0,\n",
    "        'precision': total_metrics['true_positives'] / (total_metrics['true_positives'] + total_metrics['false_positives']) if (total_metrics['true_positives'] + total_metrics['false_positives']) > 0 else 0,\n",
    "        'recall': total_metrics['true_positives'] / (total_metrics['true_positives'] + total_metrics['false_negatives']) if (total_metrics['true_positives'] + total_metrics['false_negatives']) > 0 else 0,\n",
    "        'unknown_rate': total_metrics['unknown'] / total_samples if total_samples > 0 else 0,\n",
    "        'files_processed': processed_files,\n",
    "        'files_skipped': skipped_files,\n",
    "        'confusion_matrix': total_metrics,\n",
    "        'per_file_results': all_results\n",
    "    }\n",
    "\n",
    "    # Calculate F1 score\n",
    "    if overall_metrics['precision'] + overall_metrics['recall'] > 0:\n",
    "        overall_metrics['f1'] = 2 * overall_metrics['precision'] * overall_metrics['recall'] / (overall_metrics['precision'] + overall_metrics['recall'])\n",
    "    else:\n",
    "        overall_metrics['f1'] = 0\n",
    "\n",
    "    # Save results\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(overall_metrics, f, indent=2)\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\nProcessing Complete!\")\n",
    "    print(f\"Files processed: {processed_files}\")\n",
    "    print(f\"Files skipped: {skipped_files}\")\n",
    "    print(f\"\\nOverall Accuracy: {overall_metrics['accuracy']:.4f}\")\n",
    "    print(f\"Overall Precision: {overall_metrics['precision']:.4f}\")\n",
    "    print(f\"Overall Recall: {overall_metrics['recall']:.4f}\")\n",
    "    print(f\"Overall F1 Score: {overall_metrics['f1']:.4f}\")\n",
    "    print(f\"Unknown Rate: {overall_metrics['unknown_rate']:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(f\"True Positives: {total_metrics['true_positives']}\")\n",
    "    print(f\"True Negatives: {total_metrics['true_negatives']}\")\n",
    "    print(f\"False Positives: {total_metrics['false_positives']}\")\n",
    "    print(f\"False Negatives: {total_metrics['false_negatives']}\")\n",
    "    print(f\"Unknown: {total_metrics['unknown']}\")\n",
    "    \n",
    "    # Print example cases\n",
    "    print(\"\\nPrinting Example Cases:\")\n",
    "    print_example_cases({'per_file_results': all_results}, gt_dir, pred_dir)\n",
    "\n",
    "    return overall_metrics\n",
    "\n",
    "def load_gt_file(file_path: str) -> str:\n",
    "    \"\"\"Load ground truth file and extract answer.\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data['answer'].lower().strip('.,')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gt_dir = \"/share/ssddata/sarimhashmi/posix_thesis/new_improve_stuff/thesis_hell_yeah/Thesis/paraphrase_error_iuxray_variant\"\n",
    "    pred_dir = \"/share/ssddata/sarimhashmi/posix_thesis/new_improve_stuff/thesis_hell_yeah/Thesis/med-flamingo/spell_error_posix\"\n",
    "    results = evaluate_directory(gt_dir, pred_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwenvl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
