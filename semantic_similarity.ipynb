{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 result files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid results were collected!\n",
      "Script completed with errors - no statistics available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.cuda.set_device(1)\n",
    "device = torch.device(\"cuda:1\")\n",
    "\n",
    "def load_json_file(file_path):\n",
    "    \"\"\"Load and return JSON file content.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Corrupted JSON file: {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def calculate_semantic_similarity(text1, text2, model):\n",
    "    \"\"\"Calculate semantic similarity between two texts using SBERT.\"\"\"\n",
    "    try:\n",
    "        # Encode the texts\n",
    "        embeddings = model.encode([text1, text2])\n",
    "        # Calculate cosine similarity and convert to native Python float\n",
    "        similarity = float(cosine_similarity([embeddings[0]], [embeddings[1]])[0][0])\n",
    "        return similarity\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating similarity: {str(e)}\")\n",
    "        print(f\"Text1: {text1[:100]}...\")\n",
    "        print(f\"Text2: {text2[:100]}...\")\n",
    "        return None\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\"Custom encoder for numpy types\"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,\n",
    "                          np.int16, np.int32, np.int64, np.uint8,\n",
    "                          np.uint16, np.uint32, np.uint64)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.float_, np.float16, np.float32, np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, (np.ndarray,)):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "def main():\n",
    "    # Initialize SBERT model\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
    "    \n",
    "    # Define paths\n",
    "    gt_dir = \"/ephemeral/shashmi/posix_new_improved/Thesis/paraphrase_error_iuxray_variant\"\n",
    "    results_dir = \"/ephemeral/shashmi/posix_new_improved/Thesis/paraphrase_error_posix_result_llava_1.6\"\n",
    "    \n",
    "    # Store all similarities\n",
    "    all_similarities = []\n",
    "    \n",
    "    # Get all result files\n",
    "    result_files = [f for f in os.listdir(results_dir) if f.endswith('_variants_results.json')]\n",
    "    print(f\"Found {len(result_files)} result files\")\n",
    "    \n",
    "    # Process each file\n",
    "    for result_file in tqdm(result_files, desc=\"Processing files\"):\n",
    "        try:\n",
    "            # Get corresponding GT file name\n",
    "            gt_file = result_file.replace('_results.json', '.json')\n",
    "            \n",
    "            # Construct full paths\n",
    "            gt_path = os.path.join(gt_dir, gt_file)\n",
    "            result_path = os.path.join(results_dir, result_file)\n",
    "            \n",
    "            # Check if both files exist\n",
    "            if not (os.path.exists(gt_path) and os.path.exists(result_path)):\n",
    "                print(f\"Missing file pair for {result_file}\")\n",
    "                continue\n",
    "            \n",
    "            # Load both files\n",
    "            gt_data = load_json_file(gt_path)\n",
    "            result_data = load_json_file(result_path)\n",
    "            \n",
    "            # Skip if either file is corrupted\n",
    "            if gt_data is None or result_data is None:\n",
    "                print(f\"Skipping {result_file} due to corrupted data\")\n",
    "                continue\n",
    "            \n",
    "            # Get ground truth answer\n",
    "            if 'answer' not in gt_data:\n",
    "                print(f\"No 'answer' field in {gt_file}\")\n",
    "                continue\n",
    "                \n",
    "            gt_answer = gt_data['answer']\n",
    "            \n",
    "            # Get generated responses\n",
    "            if 'trace' not in result_data or 'responses' not in result_data['trace']:\n",
    "                print(f\"Missing response data in {result_file}\")\n",
    "                continue\n",
    "                \n",
    "            responses = result_data['trace']['responses'][0]\n",
    "            \n",
    "            # Calculate similarities for each response\n",
    "            similarities = []\n",
    "            for response in responses:\n",
    "                similarity = calculate_semantic_similarity(gt_answer, response, model)\n",
    "                if similarity is not None:\n",
    "                    similarities.append(similarity)\n",
    "            \n",
    "            # Skip if no valid similarities were calculated\n",
    "            if not similarities:\n",
    "                print(f\"No valid similarities calculated for {result_file}\")\n",
    "                continue\n",
    "            \n",
    "            # Calculate average similarity for this question\n",
    "            avg_similarity = float(np.mean(similarities))\n",
    "            \n",
    "            # Store results\n",
    "            file_results = {\n",
    "                'file_name': gt_file,\n",
    "                'ground_truth': gt_answer,\n",
    "                'average_similarity': avg_similarity,\n",
    "                'individual_similarities': [float(s) for s in similarities],\n",
    "                'responses': responses\n",
    "            }\n",
    "            \n",
    "            all_similarities.append(file_results)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {result_file}: {str(e)}\")\n",
    "    \n",
    "    # Check if we have any results\n",
    "    if not all_similarities:\n",
    "        print(\"No valid results were collected!\")\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"Successfully processed {len(all_similarities)} files\")\n",
    "    \n",
    "    # Convert to DataFrame for analysis\n",
    "    df = pd.DataFrame(all_similarities)\n",
    "    \n",
    "    # Calculate overall statistics\n",
    "    overall_stats = {\n",
    "        'mean_similarity': float(df['average_similarity'].mean()),\n",
    "        'std_similarity': float(df['average_similarity'].std()),\n",
    "        'median_similarity': float(df['average_similarity'].median()),\n",
    "        'min_similarity': float(df['average_similarity'].min()),\n",
    "        'max_similarity': float(df['average_similarity'].max())\n",
    "    }\n",
    "    \n",
    "    # Save results\n",
    "    df.to_csv('semantic_similarity_results.csv', index=False)\n",
    "    \n",
    "    # Save detailed results as JSON\n",
    "    with open('semantic_similarity_detailed.json', 'w') as f:\n",
    "        json.dump({\n",
    "            'file_results': all_similarities,\n",
    "            'overall_statistics': overall_stats\n",
    "        }, f, indent=4, cls=NumpyEncoder)\n",
    "    \n",
    "    return df, overall_stats\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df, stats = main()\n",
    "    if stats is not None:\n",
    "        print(\"\\nOverall Statistics:\")\n",
    "        for key, value in stats.items():\n",
    "            print(f\"{key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(\"Script completed with errors - no statistics available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 400/400 [00:36<00:00, 10.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Statistics:\n",
      "mean_similarity: 0.6348\n",
      "std_similarity: 0.2136\n",
      "min_similarity: -0.0340\n",
      "max_similarity: 1.0000\n",
      "total_files_processed: 399\n",
      "total_files_failed: 1\n",
      "\n",
      "Number of failed files: 1\n",
      "See error_log.json for details of failed files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "torch.cuda.set_device(1)\n",
    "device = torch.device(\"cuda:1\")\n",
    "def load_and_match_files(ground_truth_dir, results_dir):\n",
    "    \"\"\"\n",
    "    Load and match corresponding ground truth and results files.\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    gt_files = [f for f in os.listdir(ground_truth_dir) if f.endswith('_variants.json')]\n",
    "    \n",
    "    for gt_file in gt_files:\n",
    "        results_file = gt_file.replace('.json', '_results_results.json')\n",
    "        if os.path.exists(os.path.join(results_dir, results_file)):\n",
    "            pairs.append((\n",
    "                os.path.join(ground_truth_dir, gt_file),\n",
    "                os.path.join(results_dir, results_file)\n",
    "            ))\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "def calculate_semantic_similarity(model, text1, text2):\n",
    "    \"\"\"\n",
    "    Calculate semantic similarity between two texts using sentence transformers.\n",
    "    \"\"\"\n",
    "    # Get embeddings and move to CPU before converting to numpy\n",
    "    embedding1 = model.encode(text1, convert_to_tensor=True)\n",
    "    embedding2 = model.encode(text2, convert_to_tensor=True)\n",
    "    \n",
    "    # Move tensors to CPU and convert to numpy\n",
    "    embedding1 = embedding1.cpu().numpy()\n",
    "    embedding2 = embedding2.cpu().numpy()\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity = np.dot(embedding1, embedding2) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))\n",
    "    return float(similarity)\n",
    "\n",
    "def analyze_semantic_similarity():\n",
    "    # Paths\n",
    "    ground_truth_dir = \"/ephemeral/shashmi/posix_new_improved/Thesis/paraphrase_error_iuxray_variant\"\n",
    "    results_dir = \"/ephemeral/shashmi/posix_new_improved/Thesis/paraphrase_error_posix_result_qwenvl\"\n",
    "    \n",
    "    # Load model\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2',device=device)\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.to('cuda:1')\n",
    "    \n",
    "    # Get matched file pairs\n",
    "    file_pairs = load_and_match_files(ground_truth_dir, results_dir)\n",
    "    \n",
    "    results = []\n",
    "    error_files = []\n",
    "    \n",
    "    # Process each pair of files\n",
    "    for gt_file, results_file in tqdm(file_pairs, desc=\"Processing files\"):\n",
    "        try:\n",
    "            # Load files\n",
    "            with open(gt_file, 'r') as f:\n",
    "                gt_data = json.load(f)\n",
    "            with open(results_file, 'r') as f:\n",
    "                results_data = json.load(f)\n",
    "            \n",
    "            # Get ground truth answer and clean it\n",
    "            gt_answer = gt_data['answer'].strip()\n",
    "            \n",
    "            # Get model responses and clean them\n",
    "            model_responses = [resp.strip() for resp in results_data['trace']['responses'][0] if resp]\n",
    "            \n",
    "            # Calculate similarities\n",
    "            similarities = []\n",
    "            for response in model_responses:\n",
    "                try:\n",
    "                    sim = calculate_semantic_similarity(model, gt_answer, response)\n",
    "                    similarities.append(sim)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error calculating similarity for response in {gt_file}: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            if similarities:  # Only add results if we got some valid similarities\n",
    "                results.append({\n",
    "                    'file_name': os.path.basename(gt_file),\n",
    "                    'semantic_similarity': np.mean(similarities),\n",
    "                    'min_similarity': np.min(similarities),\n",
    "                    'max_similarity': np.max(similarities),\n",
    "                    'std_similarity': np.std(similarities),\n",
    "                    'num_responses': len(similarities)\n",
    "                })\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_files.append((os.path.basename(gt_file), str(e)))\n",
    "            continue\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Calculate overall statistics\n",
    "    if not df.empty:\n",
    "        overall_stats = {\n",
    "            'mean_similarity': df['semantic_similarity'].mean(),\n",
    "            'std_similarity': df['semantic_similarity'].std(),\n",
    "            'min_similarity': df['semantic_similarity'].min(),\n",
    "            'max_similarity': df['semantic_similarity'].max(),\n",
    "            'total_files_processed': len(df),\n",
    "            'total_files_failed': len(error_files)\n",
    "        }\n",
    "    else:\n",
    "        overall_stats = {\n",
    "            'error': 'No valid results generated',\n",
    "            'total_files_failed': len(error_files)\n",
    "        }\n",
    "    \n",
    "    # Save results\n",
    "    df.to_csv('semantic_similarity_results.csv', index=False)\n",
    "    \n",
    "    # Save error log\n",
    "    with open('error_log.json', 'w') as f:\n",
    "        json.dump({'failed_files': error_files}, f, indent=4)\n",
    "    \n",
    "    # Save overall stats\n",
    "    with open('semantic_similarity_stats.json', 'w') as f:\n",
    "        json.dump(overall_stats, f, indent=4)\n",
    "    \n",
    "    return df, overall_stats, error_files\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df, stats, errors = analyze_semantic_similarity()\n",
    "    print(\"\\nOverall Statistics:\")\n",
    "    for key, value in stats.items():\n",
    "        print(f\"{key}: {value:.4f}\" if isinstance(value, float) else f\"{key}: {value}\")\n",
    "    \n",
    "    print(f\"\\nNumber of failed files: {len(errors)}\")\n",
    "    print(\"See error_log.json for details of failed files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
